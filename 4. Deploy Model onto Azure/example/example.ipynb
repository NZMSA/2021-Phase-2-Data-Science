{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training Example\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load libraries for creating a xgboost model of the iris dataset \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the iris data as an example\n",
    "# NOTE: For the assignment, you will need to use the data from Kaggle \n",
    "#       and process the text data into a usable format and then create \n",
    "#       a ML model that satisfies the assignment task!\n",
    "iris = datasets.load_iris() \n",
    "X = iris.data                \n",
    "y = iris.target             "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Split data into test and train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create XGBoost classifier \n",
    "xgbClf = XGBClassifier(use_label_encoder = False)\n",
    "xgbClf.fit(X_train, y_train)\n",
    "xgbClf.save_model(\"model.json\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18:54:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Deployment via Jupyter Notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Load workspace\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config(path = \"config.json\")\n",
    "print(ws)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n",
      "Workspace.create(name='MSA-ModelDeployment', subscription_id='1728fb6f-0674-4adc-b1a8-0462995e20a5', resource_group='MSA-ModelDeployment')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name = \"iris-xgboost\", model_path = \"model.json\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model iris-xgboost\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Create environment\n",
    "# env = Environment.from_existing_conda_environment(name = \"iris-xgboost\",\n",
    "                                                # conda_environment_name = \"azure\")\n",
    "\n",
    "env = Environment(name = \"iris-xgboost\")\n",
    "conda_dep = CondaDependencies()\n",
    "conda_dep.add_conda_package(\"numpy\")\n",
    "conda_dep.add_conda_package(\"xgboost\")\n",
    "env.python.conda_dependencies = conda_dep\n",
    "\n",
    "dummy_inference_config = InferenceConfig(\n",
    "    environment = env,\n",
    "    source_directory = \"./source_dir\",\n",
    "    entry_script = \"./echo_score.py\",\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"iris-xgboost\",\n",
    "    [model],\n",
    "    dummy_inference_config,\n",
    "    aci_config,\n",
    "    overwrite = True,\n",
    ")\n",
    "service.wait_for_deployment(show_output = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-07-26 18:59:24+12:00 Creating Container Registry if not exists..\n",
      "2021-07-26 18:59:39+12:00 Registering the environment..\n",
      "2021-07-26 18:59:42+12:00 Building image..\n",
      "2021-07-26 19:10:28+12:00 Generating deployment configuration.\n",
      "2021-07-26 19:10:29+12:00 Submitting deployment to compute.\n",
      "2021-07-26 19:10:39+12:00 Checking the status of deployment iris-xgboost.\n",
      "2021-07-26 19:13:37+12:00 Checking the status of inference endpoint iris-xgboost.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"<API Endpoint Here>\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"data\": [[6.1, 2.8, 4.7, 1.2]],\n",
    "}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data = data, headers = headers)\n",
    "print(response.json())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['versicolor']\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb671202a387ebf0bc7bf04476cbafa528fae566193c2efe94e2aaf8539be45"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}